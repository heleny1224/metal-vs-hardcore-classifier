{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model.load_state_dict(torch.load('DM_gtzan_best.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "wrong_predictions = []\n",
    "\n",
    "all_predicted_probs = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        all_predicted_probs.append(outputs.cpu().numpy())\n",
    "\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                wrong_predictions.append({\n",
    "                    'Audio': inputs[i],\n",
    "                    'True Label': labels[i].item(), \n",
    "                    'Predicted Label': predicted[i].item()\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7390ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "all_predicted_probs = np.concatenate(all_predicted_probs, axis=0)\n",
    "true_labels_bin = label_binarize(true_labels, classes=range(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c58564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
