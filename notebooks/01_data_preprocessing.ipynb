{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "\n",
    "input_dir = \"./data_music\"\n",
    "output_dir = \"./data_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87efc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(audio_file, output_dir, num_segments=5, original_name=\"\"):\n",
    "    try:\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "    except RuntimeError:\n",
    "        print(f\"Failed to load: {audio_file}\")\n",
    "        return\n",
    "\n",
    "    total_duration = waveform.size(1) / sample_rate\n",
    "    segment_duration = total_duration / num_segments\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start = int(i * segment_duration * sample_rate)\n",
    "        end = int((i + 1) * segment_duration * sample_rate)\n",
    "        if end > waveform.size(1):\n",
    "            end = waveform.size(1)\n",
    "        \n",
    "        segment_waveform = waveform[:, start:end]\n",
    "        segment_name = f\"{original_name}_segment_{i + 1}.wav\"\n",
    "        output_file = os.path.join(output_dir, segment_name)\n",
    "        \n",
    "        torchaudio.save(output_file, segment_waveform, sample_rate)\n",
    "\n",
    "def split_audio_files(input_dir, output_dir, num_segments=5):\n",
    "    for class_folder in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            output_class_path = os.path.join(output_dir, class_folder)\n",
    "            os.makedirs(output_class_path, exist_ok=True)\n",
    "            \n",
    "            for audio_file in os.listdir(class_path):\n",
    "                audio_file_path = os.path.join(class_path, audio_file)\n",
    "                if os.path.isfile(audio_file_path):\n",
    "                    split_audio(audio_file_path, output_class_path, num_segments, audio_file)\n",
    "\n",
    "# Split audio files\n",
    "split_audio_files(input_dir, output_dir, num_segments=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GTZAN = output_dir\n",
    "gtzan_directory_list = os.listdir(GTZAN)\n",
    "\n",
    "for root, dirs, files in os.walk(\"./data_split\"):\n",
    "    for file in files:\n",
    "        if file == \".DS_Store\":\n",
    "            os.remove(os.path.join(root, file))\n",
    "\n",
    "file_genre = []\n",
    "file_path = []\n",
    "\n",
    "for folder in gtzan_directory_list:\n",
    "    files_path = os.path.join(GTZAN, folder)\n",
    "    for audio in os.listdir(files_path):\n",
    "        file_genre.append(folder)\n",
    "        file_path.append(files_path + \"/\" + audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = pd.DataFrame(file_genre, columns=[\"Genre\"])\n",
    "path_df = pd.DataFrame(file_path, columns=[\"Path\"])\n",
    "gtzan_df = pd.concat([genre_df, path_df], axis=1)\n",
    "gtzan_df.sample(n=10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioUtil():\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "        if (sig.shape[0] == new_channel):\n",
    "            return aud\n",
    "        if (new_channel == 1):\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            resig = torch.cat([sig, sig])\n",
    "            return ((resig, sr))\n",
    "    \n",
    "    @staticmethod\n",
    "    def resample(aud, newsr):\n",
    "        sig, sr = aud\n",
    "        if (sr == newsr):\n",
    "            return aud\n",
    "        \n",
    "        num_channels = sig.shape[0]\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "        if (num_channels > 1):\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "        return ((resig, newsr))\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, max_ms):\n",
    "        sig, sr = aud\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr//1000 * max_ms\n",
    "\n",
    "        if (sig_len > max_len):\n",
    "            sig = sig[:,:max_len]\n",
    "        elif (sig_len < max_len):\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "            \n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "            \n",
    "        return (sig, sr)\n",
    "    \n",
    "    @staticmethod\n",
    "    def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig, sr = aud\n",
    "        top_db = 80\n",
    "        \n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        \n",
    "        return (spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(\"Number of available GPUs:\", device_count)\n",
    "    for i in range(device_count):\n",
    "        print(\"GPU\", i, \":\", torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sr, title=\"Waveform\", ax=None):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sr\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.plot(time_axis, waveform[0], linewidth=1)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, time_axis[-1]])\n",
    "    ax.set_title(title)\n",
    "    \n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\", ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.imshow(specgram, origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
